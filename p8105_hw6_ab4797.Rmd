---
title: "Homework 6"
author: "Ani Bilazarian"
date: "11/20/2019"
output: html_document
---

```{r setup, include=FALSE, warning = FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)
```

# Problem 1


_Reading in Birthweight Data_ 

```{r, warning = FALSE, message=FALSE}
birthweight = 
  read_csv("./data/birthweight.csv")
```


_Cleaning Birthweight Data_ 

```{r, warning = FALSE, message=FALSE}
birthweight_clean = 
  birthweight %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(mrace = as.factor(mrace),
         babysex = as.character(babysex),
         frace = as.factor(frace),
         malform = as.character(malform)) %>% 
    mutate(mrace = recode(mrace,
                   '1' = "white", 
                   '2' = "black", 
                   '3' = "asian", 
                   '4' = "puerto rican",
                   '8' = "other")) %>% 
    mutate(frace = recode(frace,
                   '1' = "white", 
                   '2' = "black", 
                   '3' = "asian", 
                   '4' = "puerto rican",
                   '8' = "other",
                   '9' = "unknown")) 
```


_Proposing a regression model based on hypothesized structure_

```{r}
fit = lm(bwt ~ mrace + fincome + gaweeks, data = birthweight_clean)

fit %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "mrace", "Mother's Race: ")) %>% 
  knitr::kable(digits = 3)
```

I chose this model as research indicates that mother's race, income, and gestational age are determinants of low birthweight. This [study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5014333/) found that African-American and Latino mothers who smoked and lived in poorer communities were three times more likely to have an infant with lower birth weight compared to non-smoking and wealthier women. 

_Adding Residuals and Fitted Values_ 

```{r}
birthweight_clean =
  modelr::add_residuals(birthweight_clean, fit) 

birthweight_clean =
modelr::add_predictions(birthweight_clean, fit)
```

_Plotting Residuals versus Fitted values_
```{r}
birthweight_clean %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(color = "red") + labs(x = "Fitted Values", y = "Residuals", title = "Plot of Residuals vs. Fitted Values")
```


_Comparing my model_ 

One using length at birth and gestational age as predictors (main effects only)

```{r}
main_effects = lm(bwt ~ blength + gaweeks, data = birthweight_clean)

main_effects %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "mrace", "Mother's Race: ")) %>% 
  knitr::kable(digits = 3)
```


One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
interaction = lm(bwt ~ blength + babysex + bhead + blength * babysex + blength * bhead + bhead * babysex + blength * bhead * babysex, data = birthweight_clean)

interaction %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "mrace", "Mother's Race: ")) %>% 
  knitr::kable(digits = 3)
```


_Plotting each model_

```{r}
  birthweight_clean %>% 
  gather_predictions(fit, main_effects, interaction) %>%
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  geom_smooth(method = "lm", color = "red") +
  facet_grid(~model)
```

_Fit models to training data and obtain RMSEs_

```{r}
cv_df = 
crossv_mc(birthweight, 100) 

cv_df = 
cv_df %>% 
mutate(
main_effects = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),

interaction = map(train, ~lm(bwt ~ blength + babysex + bhead + blength * babysex + blength * bhead + bhead * babysex + blength * bhead * babysex, data = .x)),

fit = map(train, ~lm(bwt ~ mrace + fincome + gaweeks, data = .x))
) %>% 

  mutate(
rmse_model_main_effects = map2_dbl(main_effects, test, ~rmse(model = .x, data = .y)),
rmse_model_interaction = map2_dbl(interaction, test, ~rmse(model = .x, data = .y)),
rmse_model_fit = map2_dbl(fit, test, ~rmse(model = .x, data = .y))
)
```

_Plot prediction error distribution for each model_
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
    mutate(model = str_replace(model, "model_", "model: ")) %>% 

  ggplot(aes(x = model, y = rmse)) + geom_violin(color = "blue") + labs(x = "Models", y = "RMSE")

```
We can see based on the variance in prediction error that the model with interaction terms has the greatest predictive accuracy. 


# Problem 2 

_Importing weather data_ 

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

_Produce estimate of log(Bo^*B1^) using 5000 bootstrap estimates_

```{r, warning = FALSE, message = FALSE}
set.seed(1)

weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(results) %>% 
  unnest(results) %>% 
select(term, estimate) %>% 
  pivot_wider(
names_from = term, values_from = estimate) %>% 
  unnest() %>% 
  janitor::clean_names() %>% 
mutate(log_intercept = log(intercept*tmin)) %>% 
    ggplot(aes(x = log_intercept)) + geom_density() + labs(x = "Log(Beta0 * Beta1)", y = "Density")
```

This distribution does not have heavy tails indicating that there are few outliers and data is approximately normally distributed. 

_Finding and Plotting R Squared_

```{r}
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
  select(results) %>% 
  unnest(results) %>% 
  select(r.squared) %>% 
  ggplot(aes(x = r.squared)) + geom_density() + labs(x = "R Squared", y = "Density", title = "Distribution of R Squared")
```

Similar to the log distribution, the R squared distribution does not have heavy tails indicating few outliers and data is approximately normally distributed. 